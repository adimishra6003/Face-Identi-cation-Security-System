{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import load_img, array_to_img, img_to_array, ImageDataGenerator\n",
    "# img=load_img('Aditya_test.jpg', target_size=(299,299))\n",
    "# arr=img_to_array(img)\n",
    "# arr=arr.reshape((1,)+arr.shape)\n",
    "\n",
    "datagen=ImageDataGenerator(rescale=1./255,\n",
    "                           height_shift_range=0.2,\n",
    "                           width_shift_range=0.2,\n",
    "                           zoom_range=0.2,\n",
    "                           shear_range=0.2,\n",
    "                           horizontal_flip=True,\n",
    "                           rotation_range=40,\n",
    "                           fill_mode='nearest')\n",
    "\n",
    "\n",
    "# i=0\n",
    "# for batch in datagen.flow(arr, batch_size=1, save_to_dir='Validation\\Aditya_test', save_prefix='Aditya', save_format='jpeg'):\n",
    "#     i+=1\n",
    "#     if i>20:\n",
    "#         break\n",
    "\n",
    "        \n",
    "# img=load_img('Chetan_test.jpg', target_size=(299,299))\n",
    "# arr=img_to_array(img)\n",
    "# arr=arr.reshape((1,)+arr.shape)\n",
    "\n",
    "\n",
    "# i=0\n",
    "# for batch in datagen.flow(arr, batch_size=1, save_to_dir='Validation\\Chetan_test', save_prefix='Chetan', save_format='jpeg'):\n",
    "#     i+=1\n",
    "#     if i>20:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications.xception import Xception\n",
    "# x=Xception(include_top=False, input_shape=(299,299,3), weights='imagenet')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "for layer in x.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "y=Flatten()(x.output)\n",
    "prediction=Dense(2, activation='softmax')(y)\n",
    "\n",
    "model=Model(inputs=x.input, outputs=prediction)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1114 images belonging to 2 classes.\n",
      "Found 64 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train=datagen.flow_from_directory('Final Training 224', target_size=(224,224), batch_size=5, class_mode='categorical', shuffle = True)\n",
    "test=datagen.flow_from_directory('New Validation', target_size=(224,224), batch_size=8, class_mode='categorical', shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "223/223 [==============================] - 57s 256ms/step - loss: 0.2585 - accuracy: 0.9004 - val_loss: 3.1711 - val_accuracy: 0.5312\n",
      "Epoch 2/2\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.0581 - accuracy: 0.9803 - val_loss: 1.5085 - val_accuracy: 0.4531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c7488b2048>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train,validation_data=test, epochs=2, steps_per_epoch=len(train), validation_steps=len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#To Generate photos from Videos\n",
    "\n",
    "import cv2\n",
    "vidcap=cv2.VideoCapture('C1.mp4')\n",
    "# success,image=vidcap.read()\n",
    "count=0\n",
    "success=True\n",
    "while success:\n",
    "    success, image=vidcap.read()\n",
    "    if count%20==0:\n",
    "        cv2.imwrite(\"Validation\\Chetan\\Chetan%d.jpg\" %count, image)\n",
    "    count+=1\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "x= VGG16(include_top = False , weights = 'imagenet', input_shape = (224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face_casc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-82b34c5a0312>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_extractor2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-82b34c5a0312>\u001b[0m in \u001b[0;36mface_extractor2\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mface_extractor2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mface\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mface_casc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#     if faces is ():\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'face_casc' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "def face_extractor2(img):\n",
    "   \n",
    "    face=face_casc.detectMultiScale(img, 1.3, 5)\n",
    "    \n",
    "#     if faces is ():\n",
    "#         return None\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cropped_face=img[y:y+h,x:x+w]\n",
    "        cropped_face= cv2.resize(cropped_face,(224,224))\n",
    "    return cropped_face\n",
    "\n",
    "\n",
    "\n",
    "video_cap=cv2.VideoCapture('New Train Video\\AA2.mp4')\n",
    "count=0\n",
    "while True:\n",
    "    _,frames = video_cap.read()\n",
    "    \n",
    "    \n",
    "    faces = face_extractor2(frames)\n",
    "    if count%1==0:\n",
    "        \n",
    "        cv2.imwrite(\"Final Training 224\\Aditya\\Aditya_1%d.jpg\" %count, faces)\n",
    "    count+=1\n",
    "    \n",
    "else:\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-fc45570b70da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mfaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mface_casc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mcount\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from aditya \n",
    "vid=cv2.VideoCapture('Training Video\\C5.mp4')\n",
    "face_casc=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "count=0\n",
    "success=True\n",
    "while success:\n",
    "    success, frame=vid.read()\n",
    "    faces=face_casc.detectMultiScale(frame, 1.3, 5)\n",
    "    count+=1\n",
    "    if(count%5==0):\n",
    "        for (x,y,w,h) in faces:\n",
    "            \n",
    "            cropped=frame[y:y+h,x:x+w]\n",
    "            cropped=cv2.resize(cropped, (224,224))\n",
    "            cv2.imwrite(\"Final Training 224\\Chetan\\Chetan1_%d.jpg\" %count, cropped)\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import requests\n",
    "import threading\n",
    "import json\n",
    "import random\n",
    "\n",
    "def thingspeak_post():\n",
    "#     threading.Timer(15,thingspeak_post).start()\n",
    "    val = random.randint(1,30)\n",
    "    URL = 'https://api.hingspeak.com/update?api_key='\n",
    "    KEY = 'CTU9I9ZO4VUCC5QH'\n",
    "    HEADER = '&field2={}'.format(val,val)\n",
    "    \n",
    "    NEW_URL = URL+KEY+HEADER\n",
    "    \n",
    "    print(NEW_URL)\n",
    "    data = urllib.request.urlopen(NEW_URL)\n",
    "    \n",
    "    print(data)\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     thingspeak_post()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.thingspeak.com/update?api_key=CTU9I9ZO4VUCC5QH&field1=30\n",
      "https://api.thingspeak.com/update?api_key=CTU9I9ZO4VUCC5QH&field1=6\n",
      "https://api.thingspeak.com/update?api_key=CTU9I9ZO4VUCC5QH&field1=18\n",
      "https://api.thingspeak.com/update?api_key=CTU9I9ZO4VUCC5QH&field1=18\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import urllib.request\n",
    "import requests\n",
    "import threading\n",
    "import json\n",
    "import random\n",
    "face_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def face_extractor(img):\n",
    "    faces=face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cropped_face=img[y:y+h,x:x+w]\n",
    "    return cropped_face\n",
    "\n",
    "video_capture=cv2.VideoCapture(0)\n",
    "t1 = 0\n",
    "while True:\n",
    "    _,frame=video_capture.read()\n",
    "    face=face_extractor(frame)\n",
    "    if type(face) is np.ndarray:\n",
    "        face=cv2.resize(face,(224,224))\n",
    "        im=Image.fromarray(face, 'RGB')\n",
    "        img_array=np.array(im)\n",
    "        img_array=np.expand_dims(img_array, axis=0)\n",
    "        pred=model.predict(img_array)\n",
    "        #print(pred)\n",
    "        \n",
    "        name=\"None Matching\"\n",
    "        \n",
    "        if (pred[0][0]>0.5):\n",
    "            name=\"Aditya\"\n",
    "            t1=0\n",
    "            \n",
    "        elif (pred[0][1]>0.5):\n",
    "            \n",
    "            name=\"Chetan\"\n",
    "            t1+=1\n",
    "            if(t1==125):\n",
    "                   val = random.randint(1,30)\n",
    "                   URL = 'https://api.thingspeak.com/update?api_key='\n",
    "                   KEY = 'CTU9I9ZO4VUCC5QH'\n",
    "                   HEADER = '&field1={}'.format(val,val)\n",
    "    \n",
    "                   NEW_URL = URL+KEY+HEADER\n",
    "    \n",
    "                   print(NEW_URL)\n",
    "                   data = urllib.request.urlopen(NEW_URL)\n",
    "                \n",
    "        else:\n",
    "            name=\"None Matching\"\n",
    "        cv2.putText(frame, name, (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "        \n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k==27:\n",
    "            break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Version3_VGG.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
